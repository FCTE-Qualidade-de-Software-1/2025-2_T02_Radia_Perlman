# 1. Planejamento da Avaliação

## 1.1. Objetivo da Fase

Esta fase detalha o plano de execução para a coleta de dados da Fase 4. O objetivo é traduzir as métricas definidas no GQM (Fase 2) em um conjunto de Casos de Teste (CTs) auditáveis, garantindo que a avaliação seja sistemática e repetível.

Esta página centraliza o planejamento do projeto, incluindo a rastreabilidade entre as fases, o cronograma de execução e a divisão de tarefas da equipe.

## 1.2. Método de Avaliação 

Será adotada uma abordagem orientada pelo método GQM (Goal-Question-Metric).
A coleta de dados será realizada por meio de múltiplas fontes, incluindo: formulários, videochamadas com usuários para avaliar a navegação no Oppia, gravações de tela em diferentes dispositivos, ferramentas de análise estática, análise do histórico do repositório e inspeções manuais de código.
Durante a etapa de Portabilidade, serão realizados testes práticos em múltiplos dispositivos (PC, notebook, tablet e smartphone), diferentes sistemas operacionais (Windows, Linux, Android e iOS) e variadas resoluções de tela. O objetivo é observar o comportamento responsivo do Oppia, além de verificar se a navegação, layout, desempenho e acessibilidade se mantêm consistentes nas diferentes combinações de ambientes.

A tabela apresentada a seguir assegura que todas as métricas definidas na Fase 2 estão associadas a um ou mais Casos de Teste (CTs) documentados nesta etapa, garantindo assim a rastreabilidade completa entre os objetivos do GQM e os testes planejados.

<p align="center"> <b>Tabela 1 - Tabela Geral de Métricas</b> </p>

| Característica          | Questão                                                                       | Métrica                                                          | Ferramenta / Fonte de Dados       | Plano de Coleta                                                                                                                                     | ID Caso de Teste |
| ----------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------- | --------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------- |
| **Adequação Funcional** | **Q1.1 Completude Funcional: As funções cobrem todas as tarefas essenciais?** | **M1.1: Percentual de Completude das Tarefas Essenciais**        | Testes de Cenário, Requisitos     | 1. Calcular % = (tarefas concluídas / tarefas essenciais) × 100. Hipótese: 98%. Testado via cenários de uso.                                        | CT-AF-Q1-M1      |
|                         | **Q1.2 Correção Funcional: As funções produzem resultados corretos?**         | **M2.1: Taxa de Precisão do Feedback de Aprendizado**            | Testes funcionais em questões     | 1. % = (feedbacks corretos / total) × 100. Hipótese: 100%.                                                                                          | CT-AF-Q2-M1      |
|                         |                                                                               | **M2.2: Taxa de Integridade e Recuperação de Dados**             | Testes de Estresse / Concorrência | 1. % = (operações de salvamento e recuperação bem-sucedidas / total) × 100. Hipótese: 99.5%.                                                        | CT-AF-Q2-M2      |
|                         |                                                                               | **M2.3: Taxa de Precisão de Notificação e Recuperação de Dados** | Testes End-to-End (E2E)           | 1. % = (notificações entregues corretamente no prazo / total de eventos) × 100. Hipótese: 95%. <br> Testado em cenários de submissão e atualização. | CT-AF-Q2-M3      |
|                         | **Q1.3 Apropriação Funcional: As funções facilitam o aprendizado?**           | **M3.1: Eficiência na Recuperação de Informação**                | Testes de Usabilidade             | 1. % = (buscas relevantes nas 5 primeiras / total). Hipótese: 85%.                                                                                  | CT-AF-Q3-M1      |
|                         |                                                                               | **M3.2: Adequação das Funcionalidades-Chave (Likert)**           | Questionários Likert              | Média ≥ 4.0/5. Escala aplicada a estudantes e educadores.                                                                                           | CT-AF-Q3-M2      |
| **Portabilidade** | **Q2.1 Adaptabilidade: O sistema funciona em diferentes ambientes?**     | **M1.1: Adaptabilidade ao Hardware / Dispositivos**          | Testes em dispositivos reais (PC, notebook, tablet, smartphone)                      | 1. Avaliar execução do Oppia em diferentes dispositivos físicos.<br>2. Critério: % de dispositivos em que todas as funcionalidades essenciais executam corretamente. Aceitação: ≥ 90%. | CT-P-Q1-M1       |
|                   |                                                                          | **M1.2: Adaptabilidade ao Software / Sistemas Operacionais** | Testes em Windows, Linux, Android, iOS e diferentes navegadores                      | 1. Verificar funcionamento em múltiplos SOs e navegadores (Chrome, Firefox, Edge, Safari).<br>2. Critério: % de combinações SO+navegador totalmente funcionais. Aceitação: ≥ 85%.      | CT-P-Q1-M2       |
|                   | **Q2.2 Comportamento em Diferentes Resoluções: O layout se adapta bem?** | **M1.3: Responsividade por Resolução de Tela**               | Testes manuais e gravações de tela; DevTools; dispositivos físicos                   | 1. Testar resoluções: 480p, 720p, 1080p, 1440p e 4K.<br>2. Critério: % de resoluções em que o layout mantém alinhamento, acessibilidade e navegação correta. Aceitação: ≥ 90%.         | CT-P-Q1-M3       |
|                   | **Q2.3 Instalabilidade: O sistema pode ser instalado facilmente?**       | **M2.1: Esforço de Instalação**                              | Análise do processo de instalação/local setup (quando aplicável)                     | 1. Registrar tempo e passos necessários para rodar localmente (Oppia dev setup).<br>2. Aceitação: ≤ 0.4 (escala de esforço: 0 = simples, 1 = muito difícil).                           | CT-P-Q2-M1       |
|                   |                                                                          | **M2.2: Flexibilidade de Instalação**                        | Processo de instalação                                                               | 1. Avaliar se é possível instalar com variações de ambiente (por exemplo: Node/Bazel versions).<br>2. Aceitação: 0.2 ≤ X ≤ 0.4.                                                        | CT-P-Q2-M2       |
|                   | **Q2.4 Coexistência: O sistema funciona bem com outros softwares?**      | **M3.1: Disponibilidade de Coexistência**                    | Execução em paralelo com outros apps e extensões do navegador                        | 1. Verificar se o Oppia permanece estável executando simultaneamente a outras aplicações comuns.<br>2. Aceitação ≥ 0.7.                                                                | CT-P-Q3-M1       |
|                   |                                                                          | **M3.2: Restrição/Avaria sob Coexistência**                  | Registros de erro, travamentos, conflitos                                            | 1. Avaliar % de erros que ocorrem apenas quando outros apps extensões de navegador estão ativos.<br>2. Aceitação: ≤ 0.3.                                                               | CT-P-Q3-M2       |
|                   | **Q2.5 Substituibilidade: O sistema pode ser migrado ou substituído?**   | **M4.1: Consistência de Funcionalidades**                    | Testes comparando ambientes distintos (por ex.: mudança de dispositivo ou navegador) | 1. Verificar se funcionalidades essenciais se mantêm ao trocar de dispositivo/SO.<br>2. Aceitação ≥ 0.9.                                                                               | CT-P-Q4-M1       |
|                   |                                                                          | **M4.2: Facilidade de Migração**                             | Testes de migração                                                                   | 1. Avaliar se dados, progresso e sessões são preservados ao mover entre dispositivos e navegadores.<br>2. Aceitação ≥ 0.9.                                                             | CT-P-Q4-M2       |



<p align="center"><b>Fonte: </b>Autoria de <a href="https://github.com/bolzanMGB">Othavio Bolzan</a> e <a href="https://github.com/M4RINH0">Douglas Marinho</a></p>


## 1.3. Cronograma de Execução e Divisão de Tarefas

A seguir apresenta-se o cronograma detalhado das atividades previstas para as Fases 3 e 4, contemplando a configuração do ambiente, a coleta das métricas de Adequação Funcional e Portabilidade, a consolidação dos dados obtidos e a elaboração do relatório final. As datas foram distribuídas entre 19 e 30 de novembro de 2025, garantindo uma execução organizada, sequencial e alinhada aos objetivos definidos pelo método GQM.


<p align="center"> <b>Tabela 2 - Cronograma de Coleta e Avaliação</b> </p>

| **Fase** | **Etapa (Agrupada por Característica)** | **Métricas Coletadas**                                                                                                                                                                                                                                                                                                                 | **Responsáveis**                                                                                                                                               | **Início Previsto** | **Fim Previsto** |
| -------- | --------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------- | ---------------- |
| **Fase 3**    | Configuração do Ambiente                | Preparação dos formulários, ferramentas de gravação, dispositivos, Oppia, análise estática.                                                                                                                                                                                                                                            | Todos                                                                                                                                                          | **19/11/25**        | **20/11/25**     |
| **Fase 3**    | Coleta Adequação Funcional              | **M1.1** Completude de Tarefas <br> **M2.1** Precisão do Feedback <br> **M2.2** Integridade de Dados <br> **M2.3** Precisão de Notificação e Recuperação de Dados     <br>                         **M3.1** Recuperação de Informação <br> **M3.2** Adequação Funcional (Likert)                                             | [Bianca Patrocínio](https://github.com/BiancaPatrocinio7) <br> [Pedro Dourado](https://github.com/pedrolucasdourado)                                                   | **21/11/25**        | **23/11/25**     |
| **Fase 3**    | Coleta Portabilidade                    | **M1.1** Adaptabilidade ao Hardware (testes em diferentes aparelhos como desktop, notebook, tablet e smartphone) <br> **M1.2** Adaptabilidade ao Software (testes entre navegadores e sistemas operacionais distintos) <br> **M2.1** Esforço de Instalação (instalação/execução do ambiente local do Oppia) <br> **M2.2** Flexibilidade de Instalação (variações de setup e dependências) <br> **M3.1** Coexistência (verificação de funcionamento simultâneo com outras aplicações e extensões comuns) <br> **M3.2** Restrição sob Coexistência (efeitos de conflitos ou travamentos) <br> **M4.1** Consistência em Migração (comparação de comportamento e dados entre ambientes) <br> **M4.2** Facilidade de Migração (avaliação do esforço necessário para mover instâncias) | [Brunno Fernandes](https://github.com/brunnoff) <br> [Othavio Bolzan](https://github.com/bolzanMGB) <br> [Douglas Marinho](https://github.com/M4RINH0) | **24/11/25**        | **26/11/25**     |

| **Fase 4**    | Consolidação dos Dados                  | Agrupamento e organização de gravações, formulários, análise estática, inspeções e dados do repositório.                                                                                                                                                                                                                               | Todos                                                                                                                                                          | **27/11/25**        | **28/11/25**     |
| **Fase 4**    | Análise e Relatório Final               | Aplicação do GQM, interpretação dos resultados das métricas e elaboração do relatório final.                                                                                                                                                                                                                                           | Todos                                                                                                                                                          | **29/11/25**        | **30/11/25**     |


<p align="center"><b>Fonte: </b>Autoria de <a href="https://github.com/bolzanMGB">Othavio Bolzan</a> e <a href="https://github.com/M4RINH0">Douglas Marinho</a></p>

## 1.4. Fontes de Evidência e Rastreabilidade

Os seguintes documentos, artefatos e ferramentas do Oppia serão utilizados para garantir a rastreabilidade completa da avaliação, desde a definição das métricas até a verificação dos resultados.

<p align="center"> <b>Tabela 3 -  Fontes de Evidência </b> </p>


| **Fonte**                                | **Local / Ferramenta**                                                                                                                              | **Uso**                                                                                                               |
| ---------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| **Código-Fonte (Oppia)**                 | [Repositório oficial do Oppia (GitHub)](https://github.com/oppia/oppia)                                                                             | Base primária para métricas de análise estática, inspeções e verificação de implementações reais das funcionalidades. |
| **Histórico de Desenvolvimento**         | [Git Log, Pull Requests, Issues e Discussions (GitHub)](https://github.com/oppia/oppia)                                                             | Utilizado para métricas de processo e evolução (commits, issues, mudanças em funcionalidades).                        |
| **Ambiente de Execução** | [Plataforma Oppia Web](https://www.oppia.org/)                                                                                                | Fonte de métricas coletadas via testes funcionais, questionários, logs de execução e experimentação de usuários.      |
| **Definição da Avaliação**               | [Fase 2](https://fcte-qualidade-de-software-1.github.io/2025-2_T02_Radia_Perlman/fase2/01_plano_de_medicao_gqm/)                              | Formaliza cada métrica, métodos de coleta, questões e critérios de julgamento.                                        |
| **Dados Brutos Coletados**               | [Fase 4 ](https://fcte-qualidade-de-software-1.github.io/2025-2_T02_Radia_Perlman/fase4/01_dados_brutos/) | Armazena integralmente os dados coletados nos testes, formulários e análises.                                         |
| **Relatório Final**                      | [Documento Final da Avaliação](https://fcte-qualidade-de-software-1.github.io/2025-2_T02_Radia_Perlman/fase4/03_resultados_port/)                   | Consolida dados, julgamentos, discussão e conclusões.                                                                 |

<p align="center"><b>Fonte: </b>Autoria de <a href="https://github.com/bolzanMGB">Othavio Bolzan</a></p>



## Histórico de Versões

| Versão | Data | Descrição | Autor | Revisor |
| :---: | :---: | :--- | :--- | :--- |
| `1.0` | 16/11/2025 | Criação da estrutura inicial da página | [Brunno Fernandes](https://github.com/brunnoff) | [Othavio Bolzan](https://github.com/bolzanMGB)|
| `2.0` | 17/11/2025 | Elaboração das tabelas Método de Avaliação e Cronograma de Execução  |[Othavio Bolzan](https://github.com/bolzanMGB)| [Douglas Marinho](https://github.com/M4RINH0) |
| `3.0` | 17/11/2025 | Atualização das tabelas com metricas a serem utilizadas nas medições de Portabilade  |[Othavio Bolzan](https://github.com/bolzanMGB)| [Douglas Marinho](https://github.com/M4RINH0) |
